[package]
name = "turin"
version = "0.11.0"
edition = "2024"
description = "A single-binary, event-driven LLM execution runtime with composable Lua harness scripts"

[[bin]]
name = "turin"
path = "src/main.rs"

[lib]
name = "turin"
path = "src/lib.rs"

[dependencies]
# CLI
clap = { version = "4.5", features = ["derive"] }

# Config
toml = "0.8"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Async
tokio = { version = "1.0", features = ["macros", "rt-multi-thread", "time", "sync", "process", "io-util", "fs", "signal"] }
tokio-util = { version = "0.7", features = ["rt"] }

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Inference SDK family (unified provider layer)
inference-sdk-core = { git = "https://github.com/jthum/inference-sdk-rust", branch = "main" }
anthropic-sdk = { git = "https://github.com/jthum/inference-sdk-rust", branch = "main" }
openai-sdk = { git = "https://github.com/jthum/inference-sdk-rust", branch = "main" }

# MCP SDK
mcp-sdk = { git = "https://github.com/jthum/mcp-sdk-rust", branch = "main" }

# Streaming
futures = "0.3"

# Async trait support
async-trait = "0.1"

# Unique IDs
uuid = { version = "1.0", features = ["v4"] }
glob = "0.3"
notify = "6.1"

# REPL
rustyline = "14.0"


# Database (Turso â€” pure Rust SQLite rewrite)
turso = "0.4"

# Lua harness engine (Luau dialect with sandboxing)
mlua = { version = "0.11", features = ["luau", "serialize", "async", "macros", "send"] }
tracing = { version = "0.1.44", features = ["attributes"] }
tracing-subscriber = { version = "0.3.22", features = ["fmt", "env-filter", "ansi", "json"] }
tracing-appender = "0.2.4"
tracing-log = "0.2.0"

[dev-dependencies]
tempfile = "3.10"
proptest = "1.4"
[profile.release]
opt-level = "z"     # Optimize for size
lto = true          # Enable Link Time Optimization
codegen-units = 1   # Reduce parallel codegen to improve optimization
panic = "abort"     # Remove panic unwinding to save space
strip = true        # Automatically strip symbols from binary
